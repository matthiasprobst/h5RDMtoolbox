{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install h5rdmtoolbox==1.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h5rdmtoolbox import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Planning\n",
    "\n",
    "- Decide to use HDF5 as your core file format\n",
    "- Define important attributes and their usage in a metadata convention (e.g. a YAML file)\n",
    "- Publish your convention on a repository like [Zenodo](https://zenodo.org/)\n",
    "\n",
    "At this time we assume, that we have done this already, thus we'll be using a convention published on [Zenodo (doi/rec-id: 10428822)](https://zenodo.org/records/10428822), that already exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5rdmtoolbox as h5tbx\n",
    "from h5rdmtoolbox.repository import zenodo\n",
    "from h5rdmtoolbox.tutorial import TutorialConventionZenodoRecordID, get_convention_yaml_filename\n",
    "\n",
    "import os\n",
    "os.environ['ZENODO_API_TOKEN'] = 'changeme'\n",
    "\n",
    "zenodo_repo = zenodo.ZenodoRecord(TutorialConventionZenodoRecordID)\n",
    "\n",
    "if os.environ['ZENODO_API_TOKEN'] == \"changeme\":  # you might not have the zenodo token, so we take the tutorial file for now:\n",
    "    cv = h5tbx.convention.from_yaml(get_convention_yaml_filename())\n",
    "else:\n",
    "    cv = h5tbx.convention.from_repo(zenodo_repo, 'tutorial_convention.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important step is defining the expected layout of a file. For this simple example, we \"only\" want to require users to provide the attribute \"units\" with every dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox import layout\n",
    "from h5rdmtoolbox import database\n",
    "\n",
    "lay = layout.Layout()\n",
    "spec_has_units = lay.add(\n",
    "    database.FileDB.find,\n",
    "    flt={'units': {'$exists': True}},\n",
    "    objfilter='dataset'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Collecting\n",
    "\n",
    "We start with writing data to an HDF5 file. This is syntactically almost like using `h5py`, just with a few features wrapped around it.\n",
    "\n",
    "- Fill an HDF5 file with the required data and mandatory metadata\n",
    "- Data may come in various sources, e.g. from a measurement, a simulation or a database\n",
    "- HDF5 is best for multidimensional data, but can also be used for 1D data\n",
    "- When writing the HDF5 files, the convention is automatically validating the metadata input, which are the attributes\n",
    "  or the datasets and groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start writing data to the file, we must enable the convention. This results in changing the behaviour of methods like `create_datasets` as they now require parameters like `units` for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "using(\"h5rdmtoolbox-tutorial-convention\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enable the convention:\n",
    "h5tbx.use(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27_16:35:31,120 CRITICAL [core.py:613] You don't have the permission to request https://zenodo.org/api/deposit/depositions/10428795. You may need to check your access token.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: FORBIDDEN for url: https://zenodo.org/api/deposit/depositions/10428795?access_token=changeme",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\convention\\standard_attributes.py:201\u001b[0m, in \u001b[0;36mStandardAttribute.set\u001b[1;34m(self, parent, value, attrs)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m     model_fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fields\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\h5tbx310\\lib\\typing.py:1656\u001b[0m, in \u001b[0;36m_AnnotatedAlias.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnnotated\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\h5tbx310\\lib\\typing.py:983\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__origin__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_dunder(attr):\n\u001b[1;32m--> 983\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\h5tbx310\\lib\\typing.py:983\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__origin__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_dunder(attr):\n\u001b[1;32m--> 983\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\h5tbx310\\lib\\typing.py:375\u001b[0m, in \u001b[0;36m_SpecialForm.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\n\u001b[1;32m--> 375\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(item)\n",
      "\u001b[1;31mAttributeError\u001b[0m: model_fields",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_file.hdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5tbx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperimental\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://orcid.org/0000-0001-8729-0482\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m h5:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# create a dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     h5\u001b[38;5;241m.\u001b[39mcreate_dataset(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[0;32m     11\u001b[0m                       standard_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m, make_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m     h5\u001b[38;5;241m.\u001b[39mcreate_dataset(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m                       data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[0;32m     14\u001b[0m                       standard_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_velocity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m                       units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm/s\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m                       attach_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\h5tbx310\\lib\\site-packages\\forge\\_revision.py:328\u001b[0m, in \u001b[0;36mRevision.__call__.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\u001b[38;5;28mcallable\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# pylint: disable=E1102, not-callable\u001b[39;00m\n\u001b[0;32m    327\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m inner\u001b[38;5;241m.\u001b[39m__mapper__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;241m*\u001b[39mmapped\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmapped\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\wrapper\\core.py:2278\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, attrs, **kwargs)\u001b[0m\n\u001b[0;32m   2273\u001b[0m         \u001b[38;5;66;03m# logger.debug('Creating group \"h5rdmtoolbox\" with attribute \"__h5rdmtoolbox_version__\" in file')\u001b[39;00m\n\u001b[0;32m   2274\u001b[0m         \u001b[38;5;66;03m# _tbx_grp = self.create_group('h5rdmtoolbox')\u001b[39;00m\n\u001b[0;32m   2275\u001b[0m         \u001b[38;5;66;03m# _tbx_grp.rdf.subject = 'https://schema.org/SoftwareSourceCode'\u001b[39;00m\n\u001b[0;32m   2276\u001b[0m         \u001b[38;5;66;03m# _tbx_grp.attrs['__h5rdmtoolbox_version__', 'https://schema.org/softwareVersion'] = __version__\u001b[39;00m\n\u001b[0;32m   2277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m-> 2278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m v\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\wrapper\\h5attr.py:345\u001b[0m, in \u001b[0;36mWrapperAttributeManager.__setitem__\u001b[1;34m(self, name, value, attrs)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, consts\u001b[38;5;241m.\u001b[39mDefaultValue):\n\u001b[0;32m    344\u001b[0m             value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m--> 345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m utils\u001b[38;5;241m.\u001b[39mcreate_special_attribute(\u001b[38;5;28mself\u001b[39m, name, value)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\convention\\standard_attributes.py:205\u001b[0m, in \u001b[0;36mStandardAttribute.set\u001b[1;34m(self, parent, value, attrs)\u001b[0m\n\u001b[0;32m    203\u001b[0m tmp_model \u001b[38;5;241m=\u001b[39m pydantic\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, value\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m))\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     _validated_value \u001b[38;5;241m=\u001b[39m \u001b[43mtmp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattrs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pydantic\u001b[38;5;241m.\u001b[39mValidationError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mStandardAttributeError(\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation of \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for standard attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m failed.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPydantic error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\convention\\toolbox_validators.py:47\u001b[0m, in \u001b[0;36m__validate_standard_name_table\u001b[1;34m(value, handler, info)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__validate_standard_name_table\u001b[39m(value, handler, info) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStandardNameTable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mh5rdmtoolbox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m standard_names\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstandard_names\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_snt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\convention\\standard_names\\__init__.py:23\u001b[0m, in \u001b[0;36mparse_snt\u001b[1;34m(snt)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StandardNameTable\u001b[38;5;241m.\u001b[39mfrom_dict(json\u001b[38;5;241m.\u001b[39mloads(snt))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzenodo.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m snt:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStandardNameTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_zenodo\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m fname \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(snt)\n\u001b[0;32m     26\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReading standard name table from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\convention\\standard_names\\table.py:730\u001b[0m, in \u001b[0;36mStandardNameTable.from_zenodo\u001b[1;34m(source, doi_or_recid)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrepository\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mzenodo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZenodoRecord\n\u001b[0;32m    729\u001b[0m z \u001b[38;5;241m=\u001b[39m ZenodoRecord(recid)\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _fname, file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _fname \u001b[38;5;241m==\u001b[39m filename:\n\u001b[0;32m    732\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m StandardNameTable\u001b[38;5;241m.\u001b[39mfrom_yaml(file\u001b[38;5;241m.\u001b[39mdownload())\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\repository\\zenodo\\core.py:645\u001b[0m, in \u001b[0;36mZenodoRecord.files\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfiles\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, RepositoryFile]:\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;66;03m# def _parse_download_url(filename):\u001b[39;00m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;66;03m#     if filename is None:\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;66;03m#         return filename\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;66;03m#     return f\"{self.rec_url}/{self.rec_id}/files/{filename}\"\u001b[39;00m\n\u001b[1;32m--> 645\u001b[0m     is_submitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_download_url\u001b[39m(url, filename):\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\repository\\zenodo\\core.py:601\u001b[0m, in \u001b[0;36mZenodoRecord.is_published\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_published\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    600\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if the deposit is published.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmitted\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\repository\\zenodo\\core.py:615\u001b[0m, in \u001b[0;36mZenodoRecord.json\u001b[1;34m(self, raise_for_status)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    613\u001b[0m     logger\u001b[38;5;241m.\u001b[39mcritical(\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have the permission to request \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You may need to check your access token.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 615\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m    618\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many requests message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Sleep for 60 seconds and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\h5tbx310\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: FORBIDDEN for url: https://zenodo.org/api/deposit/depositions/10428795?access_token=changeme"
     ]
    }
   ],
   "source": [
    "filename = 'my_file.hdf'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with h5tbx.File(filename,\n",
    "                mode='w',\n",
    "                data_type='experimental',\n",
    "                contact='https://orcid.org/0000-0001-8729-0482') as h5:\n",
    "    # create a dataset\n",
    "    h5.create_dataset(name='time', data=np.linspace(0, 1, 1000),\n",
    "                      standard_name='time', units='ms', make_scale=True)\n",
    "    h5.create_dataset(name='u',\n",
    "                      data=np.random.normal(10, 2, 1000),\n",
    "                      standard_name='x_velocity',\n",
    "                      units='m/s',\n",
    "                      attach_scale='time')\n",
    "    h5['u'].dims[0].attach_scale(h5['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining the metadata\n",
    "\n",
    "We already provided quite some metadata with the file. Although, attributes like \"units\" is quite self-explaining, let's associate it with a persistent identifier. In this way, the metadata becomes *FAIR*. More on this can be found [here](https://h5rdmtoolbox.readthedocs.io/en/latest/userguide/wrapper/FAIRAttributes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontolutils import M4I, QUDT_UNIT\n",
    "from rdflib import DCAT\n",
    "\n",
    "with h5tbx.File(filename, 'r+') as h5:\n",
    "    h5.u.iri['units'].predicate = 'http://qudt.org/schema/qudt/Unit'\n",
    "    h5.u.iri['units'].object = QUDT_UNIT.M_PER_SEC\n",
    "    h5.iri['contact'].predicate = M4I.orcidId\n",
    "    h5.iri['standard_name_table'].predicate = 'https://matthiasprobst.github.io/ssno#standardNameTable'\n",
    "    h5.iri['standard_name_table'].object = 'https://matthiasprobst.github.io/ssno#StandardNameTable'\n",
    "\n",
    "    h5.rdf['data_type'].definition = 'The source type of the data'  # define the meaning of the attribute with a custom text\n",
    "\n",
    "    h5.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we will see one practical effect of assigning IRIs to the metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyzing\n",
    "\n",
    "Let's open the file, inspect its content and plot a dataset.\n",
    "\n",
    "## 3.1 HDF content dump\n",
    "Use the *dump()* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(filename, mode='r') as h5:\n",
    "    # inspect the file layout and content:\n",
    "    h5.dump(collapsed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or extract metadata as a JSON-LD file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox import dump_jsonld\n",
    "print(dump_jsonld(filename,\n",
    "                  indent=2,\n",
    "                  structural=False,\n",
    "                  resolve_keys=True,\n",
    "                  context={'ssno': 'https://matthiasprobst.github.io/ssno#'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Plotting\n",
    "\n",
    "First slice the dataset. We will receive a `xr.DataArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(filename, mode='r') as h5:\n",
    "    u = h5.u[:]\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot it using the conventional way by using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "u.plot(marker='.', label='raw')\n",
    "u.rolling(time=10).mean().plot(label='rolling mean (win=10)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or do everything in just a few lines (this time with a histogram) thanks to the `xrarray` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(filename, mode='r') as h5:\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    h5.u[:].plot.hist(bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sharing your data on a repository\n",
    "\n",
    "Sharing data is important. We want to upload our HDF5 file to Zenodo for long-time storage.\n",
    "\n",
    "## 4.1 Validation\n",
    "Before doing so, let's first check if the file fulfills the requirements, which we defined in the layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = lay.validate(filename)\n",
    "res.is_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes it does. We can upload it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Upload\n",
    "Currently, only the interface class to [Zenodo](https://zenodo.org/) is implemented. It is a popular choice to publish open access data. To create and upload data, you must generate an API token. If you don't have it, skip the next step or request one from Zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox.repository import zenodo\n",
    "from h5rdmtoolbox.wrapper.jsonld import hdf2jsonld\n",
    "\n",
    "# replace with your token or set up env variable \"ZENODO_SANDBOX_API_TOKEN\"\n",
    "TOKEN = zenodo.get_api_token(sandbox=True)\n",
    "\n",
    "if TOKEN:\n",
    "    zenodo.set_api_token(sandbox=True, access_token=TOKEN)\n",
    "    repo = zenodo.ZenodoSandboxDeposit(None)  # create a new one are provide the record ID.\n",
    "\n",
    "    # Note, in the next line, we can provide a function which will extract metadata from the target file.\n",
    "    # The created JSON LD file will be uploaded to. If you don't want to upload a meta file, pass None\n",
    "    repo.upload_file(filename, metamapper=hdf2jsonld, skipND=1)  # skipND is needed by `hdf2jsonld`\n",
    "\n",
    "    # print the file names as a check:\n",
    "    for file in repo.files.values():\n",
    "        print(file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reusing\n",
    "\n",
    " - Find the data by searching through a file director\n",
    " - The root folder is the parent of the created file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdb = h5tbx.database.FileDB(filename)\n",
    "fdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find exactly one file with \"standard_name=x_velocity\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fdb.find_one({'standard_name': {'$eq': 'x_velocity'}})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable \"result\" is the found dataset (class is `LDataset`, a wrapper around a closed HDF dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
